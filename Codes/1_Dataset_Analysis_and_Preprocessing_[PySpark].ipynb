{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Drive Connection**"
      ],
      "metadata": {
        "id": "iqQb5T7_wPg-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WP5zWWl0tkeY",
        "outputId": "77e8a840-4d07-4812-bbed-8f5a7f8a9c7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Shape: (7043, 21)\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|   MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|7590-VHVEG|Female|            0|    Yes|        No|     1|          No|No phone service|            DSL|            No|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|         29.85|       29.85|   No|\n",
            "|5575-GNVDE|  Male|            0|     No|        No|    34|         Yes|              No|            DSL|           Yes|          No|             Yes|         No|         No|             No|      One year|              No|        Mailed check|         56.95|      1889.5|   No|\n",
            "|3668-QPYBK|  Male|            0|     No|        No|     2|         Yes|              No|            DSL|           Yes|         Yes|              No|         No|         No|             No|Month-to-month|             Yes|        Mailed check|         53.85|      108.15|  Yes|\n",
            "|7795-CFOCW|  Male|            0|     No|        No|    45|          No|No phone service|            DSL|           Yes|          No|             Yes|        Yes|         No|             No|      One year|              No|Bank transfer (au...|          42.3|     1840.75|   No|\n",
            "|9237-HQITU|Female|            0|     No|        No|     2|         Yes|              No|    Fiber optic|            No|          No|              No|         No|         No|             No|Month-to-month|             Yes|    Electronic check|          70.7|      151.65|  Yes|\n",
            "+----------+------+-------------+-------+----------+------+------------+----------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Mount Google Drive ---\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# --- PySpark Setup ---\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, trim, when\n",
        "from pyspark.sql.types import IntegerType, DoubleType\n",
        "\n",
        "spark = SparkSession.builder.appName(\"TelcoChurnPreprocessing\").getOrCreate()\n",
        "\n",
        "# --- Load Dataset ---\n",
        "file_path = \"/content/drive/MyDrive/CSE 4262 Project/Telco Churn.csv\"\n",
        "df = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "print(\"Shape:\", (df.count(), len(df.columns)))\n",
        "df.show(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Initial Exploration**"
      ],
      "metadata": {
        "id": "kVZifIpNwZvX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Missing Values ---\n",
        "print(\" Missing Values Per Column:\")\n",
        "print(\"-\" * 30)\n",
        "missing_counts = [(c, df.filter(col(c).isNull()).count()) for c in df.columns]\n",
        "for colname, miss in missing_counts:\n",
        "    print(f\"{colname}: {miss}\")\n",
        "print(\"\\n\")\n",
        "\n",
        "# --- Dataset Info ---\n",
        "print(\" Dataset Info:\")\n",
        "print(\"-\" * 30)\n",
        "df.printSchema()\n",
        "print(f\"Rows: {df.count()}, Columns: {len(df.columns)}\\n\")\n",
        "\n",
        "from pyspark.sql import functions as F\n",
        "\n",
        "# --- Unique Values ---\n",
        "print(\" Unique Values Per Column:\")\n",
        "print(\"-\" * 30)\n",
        "unique_counts = df.agg(*(F.countDistinct(col(c)).alias(c) for c in df.columns))\n",
        "unique_counts.show(truncate=False)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCgCojvDwb5a",
        "outputId": "dbf341c6-0603-4e8a-8de0-f26eae3c81c4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Missing Values Per Column:\n",
            "------------------------------\n",
            "customerID: 0\n",
            "gender: 0\n",
            "SeniorCitizen: 0\n",
            "Partner: 0\n",
            "Dependents: 0\n",
            "tenure: 0\n",
            "PhoneService: 0\n",
            "MultipleLines: 0\n",
            "InternetService: 0\n",
            "OnlineSecurity: 0\n",
            "OnlineBackup: 0\n",
            "DeviceProtection: 0\n",
            "TechSupport: 0\n",
            "StreamingTV: 0\n",
            "StreamingMovies: 0\n",
            "Contract: 0\n",
            "PaperlessBilling: 0\n",
            "PaymentMethod: 0\n",
            "MonthlyCharges: 0\n",
            "TotalCharges: 0\n",
            "Churn: 0\n",
            "\n",
            "\n",
            " Dataset Info:\n",
            "------------------------------\n",
            "root\n",
            " |-- customerID: string (nullable = true)\n",
            " |-- gender: string (nullable = true)\n",
            " |-- SeniorCitizen: integer (nullable = true)\n",
            " |-- Partner: string (nullable = true)\n",
            " |-- Dependents: string (nullable = true)\n",
            " |-- tenure: integer (nullable = true)\n",
            " |-- PhoneService: string (nullable = true)\n",
            " |-- MultipleLines: string (nullable = true)\n",
            " |-- InternetService: string (nullable = true)\n",
            " |-- OnlineSecurity: string (nullable = true)\n",
            " |-- OnlineBackup: string (nullable = true)\n",
            " |-- DeviceProtection: string (nullable = true)\n",
            " |-- TechSupport: string (nullable = true)\n",
            " |-- StreamingTV: string (nullable = true)\n",
            " |-- StreamingMovies: string (nullable = true)\n",
            " |-- Contract: string (nullable = true)\n",
            " |-- PaperlessBilling: string (nullable = true)\n",
            " |-- PaymentMethod: string (nullable = true)\n",
            " |-- MonthlyCharges: double (nullable = true)\n",
            " |-- TotalCharges: string (nullable = true)\n",
            " |-- Churn: string (nullable = true)\n",
            "\n",
            "Rows: 7043, Columns: 21\n",
            "\n",
            " Unique Values Per Column:\n",
            "------------------------------\n",
            "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "|customerID|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|Contract|PaperlessBilling|PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "|7043      |2     |2            |2      |2         |73    |2           |3            |3              |3             |3           |3               |3          |3          |3              |3       |2               |4            |1585          |6531        |2    |\n",
            "+----------+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------+----------------+-------------+--------------+------------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Basic Cleaning & Drop ID**"
      ],
      "metadata": {
        "id": "YCD0uYaJzkJz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import trim\n",
        "\n",
        "# --- Trim spaces in column names ---\n",
        "for c in df.columns:\n",
        "    df = df.withColumnRenamed(c, c.strip())\n",
        "\n",
        "# --- Trim whitespace in all string columns ---\n",
        "for c, dtype in df.dtypes:\n",
        "    if dtype == \"string\":\n",
        "        df = df.withColumn(c, trim(col(c)))\n",
        "\n",
        "# --- Drop customerID if exists ---\n",
        "if \"customerID\" in df.columns:\n",
        "    df = df.drop(\"customerID\")\n",
        "\n",
        "print(\"Columns now:\", df.columns)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u0t5ZYL1zlCS",
        "outputId": "4015f8d6-7c7a-4c91-8468-f9245d367362"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns now: ['gender', 'SeniorCitizen', 'Partner', 'Dependents', 'tenure', 'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod', 'MonthlyCharges', 'TotalCharges', 'Churn']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fix numeric types & missing values**"
      ],
      "metadata": {
        "id": "2X6CsdOQ0qxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, when\n",
        "from pyspark.sql.types import DoubleType, IntegerType\n",
        "\n",
        "# --- Numeric columns ---\n",
        "numeric_cols = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
        "\n",
        "# Cast numeric columns to Double\n",
        "for c in numeric_cols:\n",
        "    if c in df.columns:\n",
        "        df = df.withColumn(c, col(c).cast(DoubleType()))\n",
        "\n",
        "# Fill missing TotalCharges with median\n",
        "if \"TotalCharges\" in df.columns:\n",
        "    median_total = df.approxQuantile(\"TotalCharges\", [0.5], 0.001)[0]\n",
        "    df = df.fillna({\"TotalCharges\": median_total})\n",
        "\n",
        "# Ensure SeniorCitizen is integer (0/1)\n",
        "if \"SeniorCitizen\" in df.columns:\n",
        "    df = df.withColumn(\n",
        "        \"SeniorCitizen\",\n",
        "        when(col(\"SeniorCitizen\").isNull(), 0)\n",
        "        .otherwise(col(\"SeniorCitizen\"))\n",
        "        .cast(IntegerType())\n",
        "    )\n",
        "\n",
        "print(\"Fix numeric types & missing values.\")\n",
        "\n",
        "# --- Summary statistics (like Pandas .describe()) ---\n",
        "df.select(numeric_cols).describe().show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "pZ_04BSf0v-w",
        "outputId": "bfc45ed9-5c83-4488-beae-30c1be948eb9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fix numeric types & missing values.\n",
            "+-------+------------------+------------------+-----------------+\n",
            "|summary|            tenure|    MonthlyCharges|     TotalCharges|\n",
            "+-------+------------------+------------------+-----------------+\n",
            "|  count|              7043|              7043|             7043|\n",
            "|   mean| 32.37114865824223| 64.76169246059922|2281.912359789866|\n",
            "| stddev|24.559481023094442|30.090047097678482|2265.272185332062|\n",
            "|    min|               0.0|             18.25|             18.8|\n",
            "|    max|              72.0|            118.75|           8684.8|\n",
            "+-------+------------------+------------------+-----------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normalize service-related columns, then binary-encode**"
      ],
      "metadata": {
        "id": "DlDfeyaY1UlF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import when\n",
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# 1) Binary Yes/No columns → 1/0\n",
        "binary_cols = [\"Partner\", \"Dependents\", \"PhoneService\", \"PaperlessBilling\"]\n",
        "\n",
        "for c in binary_cols:\n",
        "    if c in df.columns:\n",
        "        df = df.withColumn(\n",
        "            c,\n",
        "            when(col(c) == \"Yes\", 1)\n",
        "            .when(col(c) == \"No\", 0)\n",
        "            .otherwise(None)\n",
        "            .cast(IntegerType())\n",
        "        )\n",
        "\n",
        "# 2) Gender: Female → 0, Male → 1\n",
        "if \"gender\" in df.columns:\n",
        "    df = df.withColumn(\n",
        "        \"gender\",\n",
        "        when(col(\"gender\") == \"Female\", 0)\n",
        "        .when(col(\"gender\") == \"Male\", 1)\n",
        "        .otherwise(None)\n",
        "        .cast(IntegerType())\n",
        "    )\n",
        "\n",
        "# 3) Multi-level service columns (Yes/No/No internet service/No phone service)\n",
        "multi_level_cols = [\n",
        "    \"MultipleLines\", \"OnlineSecurity\", \"OnlineBackup\",\n",
        "    \"DeviceProtection\", \"TechSupport\", \"StreamingTV\", \"StreamingMovies\"\n",
        "]\n",
        "\n",
        "for c in multi_level_cols:\n",
        "    if c in df.columns:\n",
        "        df = df.withColumn(\n",
        "            c,\n",
        "            when(col(c) == \"No\", 0)\n",
        "            .when(col(c) == \"Yes\", 1)\n",
        "            .when((col(c) == \"No internet service\") | (col(c) == \"No phone service\"), 2)\n",
        "            .otherwise(None)\n",
        "            .cast(IntegerType())\n",
        "        )\n",
        "\n",
        "# 4) Label: Churn → 0/1\n",
        "if \"Churn\" in df.columns:\n",
        "    df = df.withColumn(\n",
        "        \"Churn\",\n",
        "        when(col(\"Churn\") == \"Yes\", 1)\n",
        "        .when(col(\"Churn\") == \"No\", 0)\n",
        "        .otherwise(None)\n",
        "        .cast(IntegerType())\n",
        "    )\n",
        "\n",
        "print(\"Sample:\")\n",
        "df.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4EW3OnMj1VZ_",
        "outputId": "d0a12e43-5e7b-494d-9513-bf9471133e29"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:\n",
            "+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|gender|SeniorCitizen|Partner|Dependents|tenure|PhoneService|MultipleLines|InternetService|OnlineSecurity|OnlineBackup|DeviceProtection|TechSupport|StreamingTV|StreamingMovies|      Contract|PaperlessBilling|       PaymentMethod|MonthlyCharges|TotalCharges|Churn|\n",
            "+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "|     0|            0|      1|         0|   1.0|           0|            2|            DSL|             0|           1|               0|          0|          0|              0|Month-to-month|               1|    Electronic check|         29.85|       29.85|    0|\n",
            "|     1|            0|      0|         0|  34.0|           1|            0|            DSL|             1|           0|               1|          0|          0|              0|      One year|               0|        Mailed check|         56.95|      1889.5|    0|\n",
            "|     1|            0|      0|         0|   2.0|           1|            0|            DSL|             1|           1|               0|          0|          0|              0|Month-to-month|               1|        Mailed check|         53.85|      108.15|    1|\n",
            "|     1|            0|      0|         0|  45.0|           0|            2|            DSL|             1|           0|               1|          1|          0|              0|      One year|               0|Bank transfer (au...|          42.3|     1840.75|    0|\n",
            "|     0|            0|      0|         0|   2.0|           1|            0|    Fiber optic|             0|           0|               0|          0|          0|              0|Month-to-month|               1|    Electronic check|          70.7|      151.65|    1|\n",
            "+------+-------------+-------+----------+------+------------+-------------+---------------+--------------+------------+----------------+-----------+-----------+---------------+--------------+----------------+--------------------+--------------+------------+-----+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Encode Multi-class Categorical Columns**"
      ],
      "metadata": {
        "id": "XYzeyXbh2lTt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType\n",
        "\n",
        "# 1) InternetService -> Label Encoding\n",
        "if \"InternetService\" in df.columns:\n",
        "    df = df.withColumn(\n",
        "        \"InternetService\",\n",
        "        when(col(\"InternetService\") == \"No\", 0)\n",
        "        .when(col(\"InternetService\") == \"DSL\", 1)\n",
        "        .when(col(\"InternetService\") == \"Fiber optic\", 2)\n",
        "        .otherwise(None)\n",
        "        .cast(IntegerType())\n",
        "    )\n",
        "\n",
        "# 2) Contract -> Ordinal Encoding\n",
        "if \"Contract\" in df.columns:\n",
        "    df = df.withColumn(\n",
        "        \"Contract\",\n",
        "        when(col(\"Contract\") == \"Month-to-month\", 0)\n",
        "        .when(col(\"Contract\") == \"One year\", 1)\n",
        "        .when(col(\"Contract\") == \"Two year\", 2)\n",
        "        .otherwise(None)\n",
        "        .cast(IntegerType())\n",
        "    )\n",
        "\n",
        "# 3) PaymentMethod -> Label Encoding\n",
        "if \"PaymentMethod\" in df.columns:\n",
        "    df = df.withColumn(\n",
        "        \"PaymentMethod\",\n",
        "        when(col(\"PaymentMethod\") == \"Electronic check\", 0)\n",
        "        .when(col(\"PaymentMethod\") == \"Mailed check\", 1)\n",
        "        .when(col(\"PaymentMethod\") == \"Bank transfer (automatic)\", 2)\n",
        "        .when(col(\"PaymentMethod\") == \"Credit card (automatic)\", 3)\n",
        "        .otherwise(None)\n",
        "        .cast(IntegerType())\n",
        "    )\n",
        "\n",
        "print(\"Shape:\", (df.count(), len(df.columns)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vRLi5cwB2nOn",
        "outputId": "fba99c21-3842-48b9-95af-8d09de10787b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape: (7043, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Scale numeric features**"
      ],
      "metadata": {
        "id": "C3WchYQO4iA1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.functions import vector_to_array\n",
        "from pyspark.sql.functions import col\n",
        "\n",
        "# --- Select numeric columns to scale ---\n",
        "scale_cols = [c for c in [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"] if c in df.columns]\n",
        "\n",
        "# Assemble into a single features vector\n",
        "assembler = VectorAssembler(inputCols=scale_cols, outputCol=\"features\")\n",
        "df_vec = assembler.transform(df)\n",
        "\n",
        "# Apply StandardScaler (z-score scaling)\n",
        "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\", withMean=True, withStd=True)\n",
        "scaler_model = scaler.fit(df_vec)\n",
        "df_scaled = scaler_model.transform(df_vec)\n",
        "\n",
        "# Convert the vector to an array so we can index it\n",
        "df_scaled = df_scaled.withColumn(\"scaled_arr\", vector_to_array(col(\"scaled_features\")))\n",
        "\n",
        "# Extract scaled values back into original columns\n",
        "for i, c in enumerate(scale_cols):\n",
        "    df_scaled = df_scaled.withColumn(c, col(\"scaled_arr\")[i])\n",
        "\n",
        "# Drop helper columns\n",
        "df_scaled = df_scaled.drop(\"features\", \"scaled_features\", \"scaled_arr\")\n",
        "\n",
        "print(\"Scaled columns:\", scale_cols)\n",
        "df_scaled.select(scale_cols).show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rb80oVDz4hyK",
        "outputId": "ba88bede-cd45-4f64-8d53-66a8d8110e1c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scaled columns: ['tenure', 'MonthlyCharges', 'TotalCharges']\n",
            "+-------------------+--------------------+--------------------+\n",
            "|             tenure|      MonthlyCharges|        TotalCharges|\n",
            "+-------------------+--------------------+--------------------+\n",
            "|-1.2773538915070017| -1.1602405389153594| -0.9941685482090249|\n",
            "|0.06632271016746097|-0.25961050958945525|-0.17322967294207875|\n",
            "|-1.2366364187289876|-0.36263460888503846|  -0.959603165511527|\n",
            "| 0.5142149107256152| -0.7464824627121305|-0.19475026561772396|\n",
            "|-1.2366364187289876| 0.19735122115708273| -0.9404001751240282|\n",
            "+-------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving the CSV file**"
      ],
      "metadata": {
        "id": "oqOL0Jf15VYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "save_path = \"/content/drive/MyDrive/CSE 4262 Project/Preprocessed_Churn_PySpark.csv\"\n",
        "df_scaled.toPandas().to_csv(save_path, index=False)\n",
        "\n",
        "print(\"✅ File saved at:\", save_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5_Vpm7Hb4qra",
        "outputId": "96bc6f9c-9bbc-4684-aab0-06a35dcb916b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ File saved at: /content/drive/MyDrive/CSE 4262 Project/Preprocessed_Churn_PySpark.csv\n"
          ]
        }
      ]
    }
  ]
}